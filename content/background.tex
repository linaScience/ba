\chapter{Background}\label{sec:background}

\section{Machine Learning }

\subsection{Classification}

Classification \ac{ml} models predict specific categories or classes for input data.
By training on input features and labels, these models categorize unseen data.
They find use in many domains, producing outputs such as spam or not spam, positive or negative sentiment, and malignant or benign tumors.
A specific type of classification is multi-class classification which categorizes more than two classes. \cite[pp.179-182]{BishopPatternRecognition}
In this thesis, a chosen classification model will predict the next \ac{ap} a user will be nearest to based on the \ac{rssi} of the \acp{ap} and the trajectory of the user.


\subsection{Time Series Prediction}

Time series prediction is a type of supervised learning problem where a model is trained on a sequence of observations and learns to predict the next value in the sequence.
Those sequences consist of data points arranged chronologically, prevalent in numerous domains like stock prices.
Due to its inherent temporal dependencies, where subsequent data points influence previous ones, specific machine learning techniques are applied.
These include \ac{mlp}, \ac{hmm}, and \ac{rnn} models such as \ac{lstm}.
Each model is designed to capture and leverage temporal patterns within the data, predicting future trends based on historical observations. \cite{neptune-ai}


\subsection{Univariate and Multivariate Time Series}

A time series is univariate, if one observation recorded sequentially over time, e.g., temperature or stock prices.
The focus of using \ac{ml} is to understand and forecast a single variable's behavior.
In the dataset observed in this thesis, has more than just one value which is recorded sequentially over time such as \ac{rssi}, waypoint and sensor data.  
Therefore, the dataset has multiple observations were recorded over the same time intervals, \ac{ml} allows for the analysis of interrelationships and interdependencies between these variables, e.g., temperature, humidity, uv-index and wind speed.
The focus here is on delving into understanding dynamic interactions and co-movements between multiple variables

% Machine learning models
\subsection{Multilayer Perceptron}

\ac{mlp}, also known as a feedforward artificial neural network, is a class of deep learning models primarily used for supervised learning tasks.
An MLP consists of multiple layers of nodes in a directed graph, each fully connected to the next one.
Each node in one layer is connected with certain weights to every node in the following layer.
\acp{mlp} apply a series of transformations, typically nonlinear, to the input data using activation functions, such as the sigmoid or \ac{relu}, facilitating the model's ability to model complex patterns and dependencies in the data \cite{goodfellow_deep_2016}.

\subsection{Hidden Markov Model}

\ac{hmm} is a statistical model that assumes the system being modeled is a Markov process with unobserved (hidden) states\cite{hmm-rabiner-1989}.
\acp{hmm} are mainly known for their application in temporal pattern recognition, such as speech and handwriting.
They describe the probability of a sequence of observable data, which is assumed to result from a sequence of hidden states, each producing an observable output according to a particular probability distribution.

\subsection{Recurrent Neural Networks}

\ac{rnn} is an artificial neural network well-suited to sequential data because of its intrinsic design.
Unlike traditional feedforward neural networks, an \ac{rnn} possesses loops in its topology, allowing information to persist over time.
This unique characteristic enables the model to use its internal state (memory) to process sequences of inputs, making it ideally suited for tasks involving sequential data such as speech recognition, language modeling, and time series prediction\cite{elman_finding_1990}.

\subsubsection{Long Short-Term Memory}

\ac{lstm} is a special kind of RNN, capable of learning long-term dependencies, which Hochreiter and Schmidhuber introduced in 1997\cite{lstm-hochreiter}.
\acp{lstm} were designed to combat the ``vanishing gradient'' problem in traditional \acp{rnn}. 
This problem made it difficult for other neural networks to learn from data where relevant events occurred with significant gaps between them.
The key to the ability of the \acp{lstm} is its cell state and the accompanying gates (input, forget, and output gate), which regulate the flow of information in the network.


\subsection{Hyperparameter tuning}

In machine learning, hyperparameters play a vital role in model development.
These are parameters such as the learning rate, neural network layers, and the number of windows or batch sizes.
Proper selection of hyperparameters, known as hyperparameter tuning or optimization, is crucial to optimize model performance.
This iterative procedure involves exploring various hyperparameter combinations for the configuration that yields the most accurate predictions.
Hyperparameters can be tuned by, e.g., random search, which can be done manually or using libraries.
This thesis will use keras-tuner\cite{keras_tuner} to tune the hyperparameters of the \ac{lstm} model.


\section{Related Work}

Montavont et al. \cite{handover-assisted-by-gps} propose a handover decision algorithm based on the \ac{gps} location of the mobile device.
Khan et al. \cite{MLBasedHandoverPrediction2022} address the problem of handover prediction and \ac{ap} selection in dense \ac{wifi} networks with \ac{sdn}.
They use \ac{ml} models such as \ac{svr} and \ac{mlp} for estimating the throughput of the network to.
The predictions outperform the current approaches of strongest received signal first by 9.2\% and least loaded signal first by 8\%.

Both approaches do not consider the trajectory of the mobile device in the handover or \ac{ap} selection.
Furthermore, in large-scale and dense \ac{wifi} environments, \ac{gps} may not be available or not accurate enough for indoor trajectories.
While Khan et al. focuses on using \ac{ml} for throughput estimation of the network and accordingly choose the best \ac{ap} to roam to, they do not consider the trajectory of the mobile device in the \ac{ap} selection or use \ac{ml} for the \ac{ap} selection process directly.
Lastly, these approaches do not use user generated data, but synthesized data.

This thesis however will use user generated data, instead of synthesized, and will use \ac{ml} to predict the next \ac{ap} a user will be nearest to based on the \ac{rssi} of the \acp{ap} and the trajectory of the user.
The prediction will be difficult, because we do not know the location of the \acp{ap}, and factors such as walls and other obstacles may influence the \ac{rssi}.
Additionally, there is no information about the throughput or load an access point has, so the predictions cannot be use this information.

These predictions can be used to improve the handover process in \ac{wifi} networks initiated by a mobile device, because the predictions use real-world user generated data.
This thesis has a different approach, so the results of this thesis cannot be compared to the related work.

%\noindent