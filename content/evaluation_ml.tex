\chapter{Evaluation}\label{ch:evaluation}

For the evaluation of the model, I do the following:
First, we get the predictions of the test set in \texttt{X\_test}.
Since the predictions are probabilities for each class, we convert the highest probability as true labels in \texttt{y\_test}, because this value will be the predicted \ac{ap}.
Those are one-hot encoded, as described in \Cref{ch:implementation}.
Then, we decode the one-hot encoded classes to the original classes, which can be done by \texttt{inverse\_transform} with the encoder.
Finally, we select the highest probabilities of the predictions and compare it with the corresponding true label for the timestamp.
If they are equal, the prediction is correct, otherwise it is false.
The model's evaluation is seen in \Cref{fig:accuracy_epochs_100_window_3_batch_112_lstm_640}.

\begin{figure}[h]
    \includegraphics*[scale=0.8]{images/accuracy_epochs_100_window_3_batch_112_lstm_640.png}
    \caption{Accuracy of the model that the predicted \ac{ap} is among the top X.}
    \label{fig:accuracy_epochs_100_window_3_batch_112_lstm_640}
\end{figure}

We will now compare it to another approach.
Instead of predicting the top 3 \acp{ap}, we will use a heuristic approach.
The heuristic approach will predict the \ac{ap} with the highest signal strength, if this fails, the second strongest will be selected and so on to the fifth strongest.
This can be calculated by the following formula:
